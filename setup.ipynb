{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up the data.\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the size of data', (6000,))\n"
     ]
    }
   ],
   "source": [
    "data = np.load('data/strokes.npy')\n",
    "print('the size of data',data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the data has mean', (0.45000002, 0.04828767), 'and std', (0.6908155, 0.5390064))\n"
     ]
    }
   ],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "for i in range(len(data)):\n",
    "    cur_data = data[i]\n",
    "    for j in range(cur_data.shape[0]):\n",
    "        if cur_data[j,0] == 1:\n",
    "            data_x.append(cur_data[j,1])\n",
    "            data_y.append(cur_data[j,2])\n",
    "data_means = (np.mean(data_x),np.mean(data_y))\n",
    "data_stds = (np.std(data_x),np.std(data_y))\n",
    "print('the data has mean',data_means, 'and std',data_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max', 1191, 'min', 301, 'mean', 644.2076666666667)\n",
      "(2753, ' are > mean')\n"
     ]
    }
   ],
   "source": [
    "# max sequence size\n",
    "seq_len = []\n",
    "for i in range(len(data)):\n",
    "    seq_len.append(data[i].shape[0])\n",
    "print('max', max(seq_len),'min',min(seq_len),'mean',np.mean(seq_len))\n",
    "mean = np.mean(seq_len)\n",
    "seq_skew = []\n",
    "for i in range(len(data)):\n",
    "    seq_skew.append(data[i].shape[0]>mean)\n",
    "print(sum(seq_skew),' are > mean')\n",
    "# not very skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max', 96.15)\n",
      "0.039828254139581284\n"
     ]
    }
   ],
   "source": [
    "# max action size\n",
    "\n",
    "seq_len = []\n",
    "for i in range(len(data)):\n",
    "    seq_len.append(np.max(data[i]))\n",
    "print('max', max(seq_len))\n",
    "\n",
    "# check ratio of pen up and down:\n",
    "\n",
    "seq_len = np.zeros((0))\n",
    "for i in range(len(data)):\n",
    "    seq_len = np.concatenate([seq_len,data[i][:,0]],0)\n",
    "print(np.mean(seq_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataset_script\n",
    "\n",
    "# with only down strokes \n",
    "# ('the data has mean', (0.0422648, 0.56823623), 'and std', (0.20119265, 1.120318))\n",
    "# with all strokes:\n",
    "# ('the data has mean', (0.039828256, 0.41248125), 'and std', (0.19555554, 2.0786476))\n",
    "# In the paper, the data is normalized first.\n",
    "import global_variables as gv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class dataloader():\n",
    "    \n",
    "    def __init__(self,batch_limit,data_start, data_end, data_loc=gv.data_loc):\n",
    "        self.all_data = np.load(data_loc)\n",
    "        self.all_data = [self.all_data[i] for i in range(data_start,data_end)]\n",
    "        self.means = gv.means\n",
    "        self.stds = gv.stds\n",
    "        self.shuffled_index = range(len(self.all_data))\n",
    "        random.shuffle(self.shuffled_index)\n",
    "        self.all_data = [self.all_data[i] for i in self.shuffled_index]\n",
    "        self.batch_limit = batch_limit\n",
    "        \n",
    "    def shuffle_index():\n",
    "        random.shuffle(self.shuffled_index)\n",
    "        self.all_data = [self.all_data[i] for i in self.shuffled_index]\n",
    "        \n",
    "    def get_next_count(self,data,new_ar):\n",
    "        new_data = [x for x in data]\n",
    "        new_data.append(new_ar)\n",
    "        size = [len(x) for x in new_data]\n",
    "        total = max(size)*len(new_data)\n",
    "        #print(total)\n",
    "        return total\n",
    "    def get_data(self,epoch_size=gv.epoch_size):\n",
    "        cur_data_iter = 0\n",
    "        while(cur_data_iter<epoch_size):\n",
    "#             'returned here')\n",
    "            data = []\n",
    "            count = 0\n",
    "            while(self.get_next_count(data,self.all_data[cur_data_iter])<self.batch_limit):\n",
    "                data.append(self.all_data[cur_data_iter])\n",
    "                cur_data_iter +=1\n",
    "                if cur_data_iter>=epoch_size: break\n",
    "            data_inp = [np.concatenate([np.zeros((1,3)), x[:-1]],0) for x in data]\n",
    "            yield data_inp,data\n",
    "        \n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = dataloader(4000,0,5500)\n",
    "data_iter = x.get_data()\n",
    "data_inp,data_gt = next(data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cat_target = np.concatenate(data_gt,axis=0)\n",
    "x_gt = torch.autograd.Variable(torch.FloatTensor(cat_target[:,1]))\n",
    "y_gt = torch.autograd.Variable(torch.FloatTensor(cat_target[:,2]))\n",
    "pen_down_gt = torch.autograd.Variable(torch.FloatTensor(cat_target[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "seq_lengths = map(len, data)\n",
    "limit = max(seq_lengths)\n",
    "seq_tensor = Variable(torch.zeros((limit,len(data),3)))\n",
    "sorted_ind = np.argsort(seq_lengths)[::-1]\n",
    "for idx, (sample, seqlen) in enumerate(zip(data, seq_lengths)):\n",
    "    seq_tensor[:seqlen, sorted_ind[idx], :] = torch.FloatTensor(sample)\n",
    "    \n",
    "seq_lengths.sort(reverse=True)\n",
    "# seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "# seq_tensor = seq_tensor[perm_idx]\n",
    "pack = torch.nn.utils.rnn.pack_padded_sequence(seq_tensor,seq_lengths)\n",
    "hx = torch.autograd.Variable(torch.zeros(1,len(data), 300))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = simple_GRU(3, 300,121)\n",
    "output = network.gru_1(pack, hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(output[0])\n",
    "unsort_pattrn  = np.argsort(sorted_ind)\n",
    "inp_linear = []\n",
    "for j in unsort_pattrn:\n",
    "    inp_linear.append(unpacked[:unpacked_len[j],j,:])\n",
    "#print(inp_linear[0].size(),inp_linear[1].size())\n",
    "inp_linear = torch.cat(inp_linear,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3264, 121])\n"
     ]
    }
   ],
   "source": [
    "output = network.linear(inp_linear)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mixture_coef(output):\n",
    "    z = output # pen states\n",
    "    z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr = torch.split(z[:, :-1], 20, 1)\n",
    "    pen_down_prob = torch.sigmoid(z[:,2])\n",
    "\n",
    "    # process output z's into MDN paramters\n",
    "    # softmax all the pi's and pen states:\n",
    "    z_pi = torch.nn.functional.softmax(z_pi)\n",
    "    # all our actions\n",
    "    z_mu1 =  2/math.pi*40*torch.atan(z_mu1)\n",
    "    z_mu2 =  2/math.pi*40*torch.atan(z_mu2)\n",
    "\n",
    "    # exponentiate the sigmas and also make corr between -1 and 1.\n",
    "    z_sigma1 = torch.exp(z_sigma1)\n",
    "    z_sigma2 = torch.exp(z_sigma2)\n",
    "    z_corr = 0.99* 2/math.pi*torch.atan(z_corr)\n",
    "\n",
    "    r = [pen_down_prob,z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr]\n",
    "    return r\n",
    "\n",
    "def normal_2d_pdfval(x1, x2, mu1, mu2, s1, s2, rho):\n",
    "    norm1 = x1- mu1\n",
    "    norm2 = x2- mu2\n",
    "    s1s2 = s1*s2\n",
    "    # eq 25\n",
    "    z = torch.pow(norm1/s1,2) + torch.pow(norm2/s2,2) - 2 * rho*norm1*norm2/s1s2\n",
    "    neg_rho = 1 - torch.pow(rho,2)\n",
    "    result = torch.exp(-z/(2 * neg_rho))\n",
    "    denom = 2 * np.pi * s1s2* torch.sqrt(neg_rho)+1e-20\n",
    "    #print(np.unique(np.sign(result.cpu().data.numpy())),'result')\n",
    "    #print(np.unique(np.sign(denom.cpu().data.numpy())),'denom')\n",
    "    result = result/denom\n",
    "    # print(result.size())\n",
    "    return result\n",
    "\n",
    "def loss_distr(pen_down_prob, z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr,x1_data, x2_data,pen_data):\n",
    "    \"\"\"Returns a loss fn based on eq #26 of http://arxiv.org/abs/1308.0850.\"\"\"\n",
    "    # This represents the L_R only (i.e. does not include the KL loss term).\n",
    "    x1_data = torch.stack((x1_data,)*20,1)\n",
    "    x2_data = torch.stack((x2_data,)*20,1)\n",
    "    \n",
    "    result0 = normal_2d_pdfval(x1_data, x2_data, z_mu1, z_mu2, z_sigma1, z_sigma2,z_corr)\n",
    "    #print('result 0',np.unique(np.sign(result0.cpu().data.numpy())))\n",
    "    epsilon = 1e-6\n",
    "    #print(np.unique(z_pi.data.cpu().numpy()>=0))\n",
    "    # result1 is the loss wrt pen offset (L_s in equation 9 of\n",
    "    # https://arxiv.org/pdf/1704.03477.pdf)\n",
    "    result1 = result0* z_pi\n",
    "    result1 = torch.sum(result1, 1) + epsilon\n",
    "    result1 = -torch.log(result1)  # avoid log(0)\n",
    "\n",
    "    #fs = 1.0 - pen_data[:, 2]  # use training data for this\n",
    "    #fs = torch.reshape(fs, [-1, 1])\n",
    "    # Zero out loss terms beyond N_s, the last actual stroke\n",
    "    #result1 = result1* fs\n",
    "\n",
    "    # result2: loss wrt pen state, (L_p in equation 9)\n",
    "    # modify pendata to be 2 channel\n",
    "    # add softmax loss\n",
    "    result2 = softmax_loss(\n",
    "             labels=pen_data, logits=pen_down_prob)\n",
    "    #result2 = tf.reshape(result2, [-1, 1])\n",
    "    #if not self.hps.is_training:  # eval mode, mask eos columns\n",
    "    #    result2 = result2* fs\n",
    "    result = torch.mean(result1) #+ result2\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3.2722\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pen_down_prob,o_pi, o_mu1, o_mu2, o_sigma1, o_sigma2, o_corr = get_mixture_coef(output)\n",
    "loss_distr = loss_distr(o_pi, o_mu1, o_mu2, o_sigma1, o_sigma2, o_corr, x_gt, y_gt)\n",
    "loss_sigmoid =  torch.nn.BCELoss()\n",
    "# print(type(pen_down_prob.data),type(pen_down_gt.data))\n",
    "loss = loss_sigmoid(pen_down_prob,pen_down_gt)\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), 0.001,weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# models script\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import torch.nn as nn\n",
    "# import tensorboardX as tb\n",
    "\n",
    "class simple_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_size, hidden_size_1,output_size):\n",
    "        super(simple_GRU, self).__init__()\n",
    "        self.gru_1 = nn.GRU(inp_size, hidden_size_1)\n",
    "        self.linear = nn.Linear(hidden_size_1,output_size)\n",
    "\n",
    "        # for training\n",
    "        self.drop = nn.Dropout(0.4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,input, hidden, train=True):\n",
    "        # assuming tensor input k*3\n",
    "        ln, hn = self.gru_1(input, hidden)\n",
    "        rearranged = ln.squeeze(1)\n",
    "        if train: rearranged = self.drop(rearranged)\n",
    "        out1 = self.linear(self.relu(rearranged))\n",
    "        return out1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import data_loader\n",
    "import utils\n",
    "import global_variables as gv\n",
    "import models\n",
    "import argparse\n",
    "# import tensorboardX\n",
    "import numpy as np\n",
    "\n",
    "def setup(cuda,device_id=0):\n",
    "    if cuda:\n",
    "        torch.cuda.set_device(device_id)\n",
    "    train_data_loader = data_loader.dataloader(gv.batch_limit,gv.train_start_index,gv.train_end_index)\n",
    "    val_data_loader = data_loader.dataloader(gv.batch_limit,gv.val_start_index,gv.val_end_index)\n",
    "    network = models.simple_GRU(3,gv.gru_size,121)\n",
    "    network.cuda()\n",
    "    # init the network with orthogonal init and gluroot.\n",
    "    # network.wt_init()\n",
    "    \n",
    "    graves_output = models.graves_output()\n",
    "    \n",
    "    # Optimizer \n",
    "    optimizer = torch.optim.Adam(network.parameters(), gv.orig_lr, weight_decay=gv.weight_decay)\n",
    "    \n",
    "    # for le rumours \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    return train_data_loader, val_data_loader, network, graves_output, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'models.pyc'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(train_data_loader, network, graves_output,optimizer):\n",
    "    \n",
    "    data_fetcher = train_data_loader.get_data()\n",
    "    for iter,(data,data_gt) in enumerate(data_fetcher):\n",
    "        if iter%100 == 0 : print('cur_iter',iter)\n",
    "        cat_target = np.concatenate(data_gt,axis=0)\n",
    "        x_gt = torch.autograd.Variable(torch.FloatTensor(cat_target[:,1]))\n",
    "        y_gt = torch.autograd.Variable(torch.FloatTensor(cat_target[:,2]))\n",
    "        pen_down_gt = torch.autograd.Variable(torch.FloatTensor(cat_target[:,0]))\n",
    "        output = network.forward_unlooped(data,cuda=True)\n",
    "        pen_down_prob,o_pi, o_mu1, o_mu2, o_sigma1, o_sigma2, o_corr = graves_output.get_mixture_coef(output)\n",
    "        loss_distr = graves_output.loss_distr(o_pi, o_mu1, o_mu2, o_sigma1, o_sigma2, o_corr, x_gt, y_gt)\n",
    "        \n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss_distr.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def val(val_data_loader,network,graves_output):\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cur_iter', 0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "addmm_ received an invalid combination of arguments - got (int, int, torch.FloatTensor, torch.cuda.FloatTensor), but expected one of:\n * (torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n * (float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-13302f593704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_learning_rate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraves_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'==========TRAIN Epoch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"COMPLETE ====================\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgraves_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-baddc6e22558>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_data_loader, network, graves_output, optimizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my_gt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpen_down_gt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_unlooped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mpen_down_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_mu1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_mu2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_sigma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_sigma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_corr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraves_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_mixture_coef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss_distr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraves_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_distr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_mu1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_mu2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_sigma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_sigma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_corr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_gt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_gt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data1/aditya/the_Graves-ey_font/models.pyc\u001b[0m in \u001b[0;36mforward_unlooped\u001b[1;34m(self, data, train, cuda)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0munpacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munpacked_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mdropout_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         )\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, weight, hidden)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0mnexth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[0mhy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mflat_hidden\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                 \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mGRUCell\u001b[1;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGRUCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mgi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mgh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m# cuBLAS doesn't support 0 strides in sger, so we can't use expand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: addmm_ received an invalid combination of arguments - got (int, int, torch.FloatTensor, torch.cuda.FloatTensor), but expected one of:\n * (torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n * (float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2)\n * (float beta, float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2)\n"
     ]
    }
   ],
   "source": [
    "train_data_loader, val_data_loader, network, graves_output,optimizer = setup(True,0)\n",
    "for epoch in range(gv.total_epochs):\n",
    "    utils.adjust_learning_rate(optimizer, epoch,gv.orig_lr)\n",
    "    train_data_loader.shuffle_index()\n",
    "    train(train_data_loader, network, graves_output,optimizer)\n",
    "    print('==========TRAIN Epoch',iter+1,\"COMPLETE ====================\")\n",
    "    loss = val(val_data_loader,network,graves_output)\n",
    "    print('==========val Epoch',iter+1,\"COMPLETE ====================\")\n",
    "    # add a is best checker\n",
    "    utils.save_checkpoint({\n",
    "           'epoch': epoch + 1,\n",
    "           'arch': 'res18',\n",
    "           'loss': loss,\n",
    "           'model_state_dict': network.state_dict(),\n",
    "           'optimizer' : optimizer.state_dict(),\n",
    "        },filename = 'weights/simple_GRU_'+str(epoch+1)+'.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
